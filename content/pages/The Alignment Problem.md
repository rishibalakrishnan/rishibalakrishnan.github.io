---
title: The Alignment Problem
tags:
categories:
date: 2023-01-30
lastMod: 2023-01-30
---
Dwork, then at Microsoft Research, came up to Berkeley to meet with fellow computer scientist Amos Fiat. They spent the entire day talking. By lunchtime, as they sat down together in beloved local restaurant Chez Panisse

One engineer I spoke with complained that his management repeatedly stressed the importance of making sure that models aren’t skewed by sensitive attributes like gender and race—but his company’s privacy policy prevents him and the other machine-learning engineers from accessing the protected attributes of the records they’re working with. So, at the end of the day, they have no idea if the models are biased or not.
Omitting the protected attribute makes it impossible not only to measure this bias but also to mitigate it. For instance, a machine-learning model used in a recruiting context might penalize a candidate for not having had a job in the prior year. We might not want this penalty applied to pregnant women or recent mothers, however—but this will be difficult if the model must be “gender-blind” and can’t include gender itself, nor something so strongly connected to it as pregnancy.38
“The most robust fact in the research area,” Hardt says, “is that fairness through blindness doesn’t work. That’s the most established and most robust fact in the entire research area.”39
It will take time for this idea to percolate from the computer scientists through to legal scholars, policy makers, and the public at large, but it has begun making its way. “There may be cases where allowing an algorithm to consider protected class status can actually make outcomes fairer,” as a

pany’s privacy policy prevents him and the other machine-learning engineers from accessing the protected attributes of the records they’re working with. So, at the end of the day, they have no idea if the models are biased or not.

“I said, what I’m worried about is things that the neural net has learned that are just as risky as asthma but the rule-based system didn’t learn.” Because the neural net is more powerful, more flexible, it was capable of learning things that the rule-based system didn’t. This, after all, is the advantage of neural networks—and the reason Caruana’s neural net had won the group’s internal contest. “I said it’s those things that will make us not use this model. Because we don’t know what’s in it that we would need to fix. So it’s this transparency problem with the neural net that ultimately caused me to say we’re not going to use it.
