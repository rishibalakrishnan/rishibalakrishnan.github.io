---
title: The Atlas of AI
tags:
categories:
date: 2023-01-30
lastMod: 2023-01-30
---
In the case of AI, there is no singular black box to open, no secret to expose, but a multitude of interlaced systems of power. Complete transparency, then, is an impossible goal

Strubell’s team found that running only a single NLP model produced more than 660,000 pounds of carbon dioxide emissions, the equivalent of five gas-powered cars over their total lifetime (including their manufacturing) or 125 round-trip flights from New York to Beijing.

This racialized appearance signaled exotic otherness, at a time when the elites of Vienna would drink Turkish coffee and dress their servants in Turkish costumes.30 It came to be known as the Mechanical Turk

When the matching processes of AI are truly hidden and people are kept unaware of why or how they receive forms of advantage or disadvantage, a collective political response is needed—even as it becomes more difficult.

Once the theory emerged that it is possible to assess internal states by measuring facial movements and the technology was developed to measure them, people willingly adopted the underlying premise. The theory fit what the tools could do.

The more complex issues of context, conditioning, relationality, and cultural factors are hard to reconcile with the current disciplinary approaches of computer science or the ambitions of the commercial tech sector. So Ekman’s basic emotional categories became standard. More subtle approaches, like Mead’s middle ground, were largely overlooked.

While the NSA has been a focus for privacy concerns, less attention is given to the growing commercial surveillance sector, which aggressively markets its tools and platforms to police departments and public agencies.

provide their police with a suite of ALPR systems to use on patrol, along with access to Vigilant’s database.64 In return, the local governments provide Vigilant with records of outstanding arrest warrants and overdue court fees. Any license plates flagged to match those associated with outstanding fines in the database are fed into police officers’ mobile systems, altering them to pull these drivers over.

police were incentivized to promote the Neighbors app and for every qualifying download they would receive credits toward free Ring cameras.73 The result was a “self-perpetuating surveillance network: more people download Neighbors, more people get Ring, surveillance footage proliferates, and police can request whatever they want,”

fighting-age males coming off of boats that looked awfully healthy. Was that a cause for concern in regard to ISIS and, if so, could this type of solution be helpful?”83
From the safe distance of their corporate offices, IBM’s data scientists viewed the problem as one best addressed through data extraction and social media analysis. Setting aside the many variables that existed in the conditions of makeshift refugee camps and the dozens of assumptions used to classify terrorist behavior, IBM created an experimental “terrorist credit score” to weed out ISIS fighters from refugees

Our worldwide team, some of the folks in Europe, were getting feedback that there were some concerns that within these asylum-seeking populations that had been starved and dejected, there were fighting-age males coming off of boats that looked awfully healthy. Was that a cause for concern in regard to ISIS and, if so, could this type of solution be helpful?”83
From the safe distance of their corporate offices, IBM’s data scientists viewed the problem as one best addressed through data extraction and social media analysis. Setting aside the many variables that existed in the conditions of makeshift refugee camps and the dozens of assumptions used to classify terrorist behavior, IBM created an experimental “terrorist credit score” to weed out ISIS fighters from refugees

he directed that a matching algorithm be used to implement the state’s “fugitive felon” policy, which sought automatically to disqualify individuals from food assistance based on outstanding felony warrants. Between 2012 and 2015, the new system inaccurately matched more than nineteen thousand Michigan residents and auto

he directed that a matching algorithm be used to implement the state’s “fugitive felon” policy, which sought automatically to disqualify individuals from food assistance based on outstanding felony warrants. Between 2012 and 2015, the new system inaccurately matched more than nineteen thousand Michigan residents and automatically disqualified each of them from food assistance.88

MiDAS was designed to treat almost any data discrepancies or inconsistencies in an individual’s record as potential evidence of illegal conduct. The system inaccurately identified more than forty thousand Michigan residents of suspected fraud.

The NSA’s distinctive methods and tools have filtered down to classrooms, police stations, workplaces, and unemployment offices. It is the result of enormous investments, of de facto forms of privatization, and the securitization of risk and fear

The standard accounts of AI often center on a kind of algorithmic exceptionalism—the idea that because AI systems can perform uncanny feats of computation, they must be smarter and more objective than their flawed human creators.

Enchanted determinism has two dominant strands, each a mirror image of the other. One is a form of tech utopianism that offers computational interventions as universal solutions applicable to any problem. The other is a tech dystopian perspective that blames algorithms for their negative outcomes as though they are independent agents, without contending with the contexts that shape them and in which they operate. At an extreme, the tech dystopian narrative ends in the singularity, or superintelligence—the theory that a machine intelligence could emerge that will ultimately dominate or destroy humans.10

These dystopian and utopian discourses are metaphysical twins: one places its faith in

This is not magic; it is statistical analysis at scale. Yet the tales of preternatural machine intelligence persist.11 Over and over, we see the ideology of Cartesian dualism in AI: the fantasy that AI systems are disembodied brains that absorb and produce knowledge independently from their creators, infrastructures, and the world at large.

AI began as a major public project of the twentieth century and was relentlessly privatized to produce enormous financial gains for the tiny minority at the top of the extraction pyramid.

Many of AI’s achievements have depended on boiling things down to a terse set of formalisms based on proxies: identifying and naming some features while ignoring or obscuring countless others. To adapt a phrase from philosopher Babette Babich, machine learning exploits what it does know to predict what it does not know: a game of repeated approximations. Datasets are also proxies—stand-ins for what they claim to measure. Put simply, this is transmuting difference into computable sameness. This kind of knowledge schema recalls what Friedrich Nietzsche described as “the falsifying of the multifarious and incalculable into the identical, similar, and calculable.”

Should we not seek to democratize it? Could there not be an AI for the people that is reoriented toward justice and equality rather than industrial extraction and discrimination? This may seem appealing, but as we have seen throughout this book, the infrastructures and forms of power that enable and are enabled by AI skew strongly toward the centralization of control. To suggest that we democratize AI to reduce asymmetries of power is a little like arguing for democratizing weapons manufacturing in the service of peace.
